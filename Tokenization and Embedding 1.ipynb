{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41ebd9a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73e134b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0aa4510",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6baea474",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words_list = nltk.corpus.stopwords.words(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d9ca0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemma_nltk = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd2afe90",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"J:/Data science/data/NLP/disaster/train.csv\")\n",
    "test_df = pd.read_csv(\"J:/Data science/data/NLP/disaster/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0187348c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "afbc0b14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7613, 5), (3263, 4))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape , test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "20785705",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4342\n",
       "1    3271\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5edf7bb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2644</th>\n",
       "      <td>3796</td>\n",
       "      <td>destruction</td>\n",
       "      <td>NaN</td>\n",
       "      <td>So you have a new weapon that can cause un-ima...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2227</th>\n",
       "      <td>3185</td>\n",
       "      <td>deluge</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The f$&amp;amp;@ing things I do for #GISHWHES Just...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5448</th>\n",
       "      <td>7769</td>\n",
       "      <td>police</td>\n",
       "      <td>UK</td>\n",
       "      <td>DT @georgegalloway: RT @Galloway4Mayor: ÛÏThe...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>191</td>\n",
       "      <td>aftershock</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Aftershock back to school kick off was great. ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6845</th>\n",
       "      <td>9810</td>\n",
       "      <td>trauma</td>\n",
       "      <td>Montgomery County, MD</td>\n",
       "      <td>in response to trauma Children of Addicts deve...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id      keyword               location  \\\n",
       "2644  3796  destruction                    NaN   \n",
       "2227  3185       deluge                    NaN   \n",
       "5448  7769       police                     UK   \n",
       "132    191   aftershock                    NaN   \n",
       "6845  9810       trauma  Montgomery County, MD   \n",
       "\n",
       "                                                   text  target  \n",
       "2644  So you have a new weapon that can cause un-ima...       1  \n",
       "2227  The f$&amp;@ing things I do for #GISHWHES Just...       0  \n",
       "5448  DT @georgegalloway: RT @Galloway4Mayor: ÛÏThe...       1  \n",
       "132   Aftershock back to school kick off was great. ...       0  \n",
       "6845  in response to trauma Children of Addicts deve...       0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_shuffled = train_df.sample(frac=1, random_state=42)\n",
    "# shuffle with random_state=42 for reproducibility\n",
    "train_df_shuffled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f5c1cf5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target: 1 (real disaster)\n",
      "Text:\n",
      "Christian Attacked by Muslims at the Temple Mount after Waving Israeli Flag via Pamela Geller - ... http://t.co/yUBKHf9iyh\n",
      "\n",
      "---\n",
      "\n",
      "Target: 0 (not real disaster)\n",
      "Text:\n",
      "Deal of The Day : http://t.co/US0qQqhQVj Brand New DSERIALPCILP Lava Computer PCI Bus Dual Serial 16550 Board  #eÛ_ http://t.co/l0b14SJ7JB\n",
      "\n",
      "---\n",
      "\n",
      "Target: 1 (real disaster)\n",
      "Text:\n",
      "I came up with an idea of a fragrance concept for a bath bomb called The Blood of my Enemies. So you can say that's what you bathe in.\n",
      "\n",
      "---\n",
      "\n",
      "Target: 0 (not real disaster)\n",
      "Text:\n",
      "@Collapsed thank u\n",
      "\n",
      "---\n",
      "\n",
      "Target: 0 (not real disaster)\n",
      "Text:\n",
      "Woke up to Drake body bagging Meek again!! Meek u can't out spit ya girlfriend... Just lay down Man.... NOT Right... http://t.co/6CraEKc9wb\n",
      "\n",
      "---\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "random_index = random.randint(0 , len(train_df))\n",
    "for row in train_df_shuffled[['text' , 'target']][random_index:random_index+5].itertuples():\n",
    "    _ , text , target = row\n",
    "    print(f\"Target: {target}\", \"(real disaster)\" if target > 0 else \"(not real disaster)\")\n",
    "    print(f\"Text:\\n{text}\\n\")\n",
    "    print(\"---\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a2e95626",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2644    So you have a new weapon that can cause un-ima...\n",
       "2227    The f$&amp;@ing things I do for #GISHWHES Just...\n",
       "5448    DT @georgegalloway: RT @Galloway4Mayor: ÛÏThe...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_shuffled['text'][:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "66310514",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = \"\".join([word.lower() for word in text if word not in string.punctuation])\n",
    "    tokens = word_tokenize(text)\n",
    "    text = \" \".join([lemma_nltk.lemmatize(word) for word in tokens if word not in stop_words_list])\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ab5659a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_shuffled['text'] = train_df_shuffled['text'].apply(lambda x:clean_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4db7e9a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2644            new weapon cause unimaginable destruction\n",
       "2227    famping thing gishwhes got soaked deluge going...\n",
       "5448    dt georgegalloway rt galloway4mayor ûïthe col...\n",
       "132     aftershock back school kick great want thank e...\n",
       "6845    response trauma child addict develop defensive...\n",
       "                              ...                        \n",
       "5226    eganator2000 arent many obliteration server al...\n",
       "5390    panic attack bc dont enough money drug alcohol...\n",
       "860     omron hem712c automatic blood pressure monitor...\n",
       "7603    official say quarantine place alabama home pos...\n",
       "7270    moved england five year ago today whirlwind ti...\n",
       "Name: text, Length: 7613, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_shuffled.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2eb94009",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2644</th>\n",
       "      <td>3796</td>\n",
       "      <td>destruction</td>\n",
       "      <td>NaN</td>\n",
       "      <td>new weapon cause unimaginable destruction</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2227</th>\n",
       "      <td>3185</td>\n",
       "      <td>deluge</td>\n",
       "      <td>NaN</td>\n",
       "      <td>famping thing gishwhes got soaked deluge going...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5448</th>\n",
       "      <td>7769</td>\n",
       "      <td>police</td>\n",
       "      <td>UK</td>\n",
       "      <td>dt georgegalloway rt galloway4mayor ûïthe col...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>191</td>\n",
       "      <td>aftershock</td>\n",
       "      <td>NaN</td>\n",
       "      <td>aftershock back school kick great want thank e...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6845</th>\n",
       "      <td>9810</td>\n",
       "      <td>trauma</td>\n",
       "      <td>Montgomery County, MD</td>\n",
       "      <td>response trauma child addict develop defensive...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id      keyword               location  \\\n",
       "2644  3796  destruction                    NaN   \n",
       "2227  3185       deluge                    NaN   \n",
       "5448  7769       police                     UK   \n",
       "132    191   aftershock                    NaN   \n",
       "6845  9810       trauma  Montgomery County, MD   \n",
       "\n",
       "                                                   text  target  \n",
       "2644          new weapon cause unimaginable destruction       1  \n",
       "2227  famping thing gishwhes got soaked deluge going...       0  \n",
       "5448  dt georgegalloway rt galloway4mayor ûïthe col...       1  \n",
       "132   aftershock back school kick great want thank e...       0  \n",
       "6845  response trauma child addict develop defensive...       0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_shuffled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3cc6932e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = train_df_shuffled['text']\n",
    "y = train_df_shuffled['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a7d14aa2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2644            new weapon cause unimaginable destruction\n",
       "2227    famping thing gishwhes got soaked deluge going...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5cc750e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2644    1\n",
       "2227    0\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "48c1852d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train ,x_test , y_train , y_test = train_test_split(x,y,test_size=0.30,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "449da9a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2710    detonation fashionable mountaineering electron...\n",
       "3250    men escape car engulfed flame parley canyon cr...\n",
       "78      i77 mile marker 31 40 south mooresville iredel...\n",
       "1621    greece tax revenue collapse debt crisis contin...\n",
       "2528    afraid sudden fear neither desolation wicked c...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "029d09f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4955    dfr ep016 monthly meltdown dnbheaven 20150806 ...\n",
       "584     fedex longer transport bioterror germ wake ant...\n",
       "7411    gunman kill four el salvador bus attack suspec...\n",
       "5950      camilacabello97 internally externally screaming\n",
       "5541    radiation emergency preparedness start knowing...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "a4ed5f09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2470    1\n",
       "3455    0\n",
       "1977    0\n",
       "7216    0\n",
       "1028    0\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "7c7c0a81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4955    0\n",
       "584     0\n",
       "7411    1\n",
       "5950    1\n",
       "5541    1\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "76f9eb9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6090,), (1523,))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape , y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "38c30b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6d9a8164",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TextVectorization(max_tokens=None,\n",
    "                               standardize=\"lower_and_strip_punctuation\",\n",
    "                               split=\"whitespace\",\n",
    "                               ngrams=None,\n",
    "                               output_mode=\"int\",\n",
    "                               output_sequence_length=None)\n",
    "                              # appad_to_max_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e47e09bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2710    detonation fashionable mountaineering electron...\n",
       "3250    men escape car engulfed flame parley canyon cr...\n",
       "78      i77 mile marker 31 40 south mooresville iredel...\n",
       "1621    greece tax revenue collapse debt crisis contin...\n",
       "2528    afraid sudden fear neither desolation wicked c...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b0ab1678",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61134"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = sum([len(i.split()) for i in x_train])\n",
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6230b174",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6090"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_len = len(x_train)\n",
    "x_train_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "86d769b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg = words / x_train_len\n",
    "round(avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6ba25ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output_sequence_length = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "fad87be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_tokens = 10000\n",
    "max_sent_length = 10 \n",
    "\n",
    "text_vectorizer = TextVectorization(max_tokens=max_tokens,\n",
    "                                    output_sequence_length=max_sent_length,\n",
    "                                   output_mode=\"int\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "68132fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_vectorizer.adapt(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "9c446b31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[  1   1  50   1   1 449   0   0   0   0]], shape=(1, 10), dtype=int64)\n",
      "shape (1, 10)\n"
     ]
    }
   ],
   "source": [
    "sample_sentence = \"There's a flood in my street!\"\n",
    "print(text_vectorizer([sample_sentence]))\n",
    "print(\"shape\",text_vectorizer([sample_sentence]).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "2ae08051",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[  1   1  50   1   1 449   1   1   1  79]], shape=(1, 10), dtype=int64)\n",
      "shape (1, 10)\n"
     ]
    }
   ],
   "source": [
    "sample_sentence = \"There's a flood in my street you are very good student and i have mony\"\n",
    "print(text_vectorizer([sample_sentence]))\n",
    "print(\"shape\",text_vectorizer([sample_sentence]).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "55e50efa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original text:\n",
      "guess ill never able go mayhem      \n",
      "\n",
      "Vectorized version:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 10), dtype=int64, numpy=\n",
       "array([[1090,  334,  133, 1322,   30,  684,    0,    0,    0,    0]],\n",
       "      dtype=int64)>"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_sentence = random.choice(x_train)\n",
    "print(f\"Original text:\\n{random_sentence}\\\n",
    "      \\n\\nVectorized version:\")\n",
    "text_vectorizer([random_sentence])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "50b7ba57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " '[UNK]',\n",
       " 'like',\n",
       " 'fire',\n",
       " 'im',\n",
       " 'amp',\n",
       " 'u',\n",
       " 'get',\n",
       " 'via',\n",
       " 'new',\n",
       " 'people',\n",
       " 'news',\n",
       " 'one',\n",
       " 'dont',\n",
       " 'video',\n",
       " '2',\n",
       " 'time',\n",
       " 'emergency',\n",
       " 'disaster',\n",
       " 'body',\n",
       " 'year',\n",
       " 'day',\n",
       " 'family',\n",
       " 'storm',\n",
       " 'home',\n",
       " 'still',\n",
       " 'building',\n",
       " 'say',\n",
       " 'life',\n",
       " 'would',\n",
       " 'go',\n",
       " 'police',\n",
       " 'crash',\n",
       " 'world',\n",
       " 'back',\n",
       " 'train',\n",
       " 'suicide',\n",
       " 'california',\n",
       " 'bomb',\n",
       " 'man',\n",
       " 'see',\n",
       " 'car',\n",
       " 'burning',\n",
       " 'look',\n",
       " 'know',\n",
       " 'rt',\n",
       " 'got',\n",
       " 'first',\n",
       " 'death',\n",
       " 'going',\n",
       " 'flood',\n",
       " 'attack',\n",
       " 'make',\n",
       " 'nuclear',\n",
       " 'want',\n",
       " 'love',\n",
       " 'war',\n",
       " 'cant',\n",
       " 'accident',\n",
       " 'youtube',\n",
       " 'let',\n",
       " 'today',\n",
       " 'killed',\n",
       " 'woman',\n",
       " 'two',\n",
       " 'weapon',\n",
       " 'could',\n",
       " 'take',\n",
       " 'many',\n",
       " '3',\n",
       " 'watch',\n",
       " 'dead',\n",
       " 'need',\n",
       " 'way',\n",
       " 'injury',\n",
       " 'full',\n",
       " 'think',\n",
       " 'may',\n",
       " 'hiroshima',\n",
       " 'good',\n",
       " 'wildfire',\n",
       " 'last',\n",
       " 'service',\n",
       " 'bag',\n",
       " 'collapse',\n",
       " 'na',\n",
       " 'help',\n",
       " 'come',\n",
       " 'best',\n",
       " 'work',\n",
       " 'mass',\n",
       " 'plan',\n",
       " 'kill',\n",
       " 'god',\n",
       " 'even',\n",
       " 'city',\n",
       " 'bombing',\n",
       " 'black',\n",
       " 'lol',\n",
       " 'fatality',\n",
       " 'really',\n",
       " 'please',\n",
       " 'mh370',\n",
       " 'fatal',\n",
       " 'legionnaire',\n",
       " 'army',\n",
       " 'another',\n",
       " 'wreck',\n",
       " 'pm',\n",
       " 'feel',\n",
       " 'youre',\n",
       " 'water',\n",
       " 'right',\n",
       " 'photo',\n",
       " 'fear',\n",
       " 'much',\n",
       " 'hostage',\n",
       " 'northern',\n",
       " 'forest',\n",
       " '5',\n",
       " '4',\n",
       " 'top',\n",
       " 'report',\n",
       " 'live',\n",
       " 'hot',\n",
       " 'great',\n",
       " '1',\n",
       " 'bomber',\n",
       " 'school',\n",
       " 'obama',\n",
       " 'hit',\n",
       " 'damage',\n",
       " 'stop',\n",
       " 'never',\n",
       " 'latest',\n",
       " 'japan',\n",
       " 'getting',\n",
       " 'every',\n",
       " '2015',\n",
       " '\\x89û',\n",
       " 'thing',\n",
       " 'old',\n",
       " 'house',\n",
       " 'since',\n",
       " 'said',\n",
       " 'read',\n",
       " 'fall',\n",
       " 'casualty',\n",
       " 'thunderstorm',\n",
       " 'thats',\n",
       " 'state',\n",
       " 'siren',\n",
       " 'found',\n",
       " 'flooding',\n",
       " 'ever',\n",
       " 'evacuation',\n",
       " 'cause',\n",
       " 'without',\n",
       " 'guy',\n",
       " 'content',\n",
       " 'boy',\n",
       " 'wave',\n",
       " 'truck',\n",
       " 'story',\n",
       " 'shit',\n",
       " 'official',\n",
       " 'near',\n",
       " 'movie',\n",
       " 'atomic',\n",
       " 'sound',\n",
       " 'show',\n",
       " 'night',\n",
       " 'malaysia',\n",
       " 'girl',\n",
       " 'fucking',\n",
       " 'food',\n",
       " 'debris',\n",
       " 'cross',\n",
       " 'bloody',\n",
       " 'wind',\n",
       " 'weather',\n",
       " 'warning',\n",
       " 'there',\n",
       " 'road',\n",
       " 'flame',\n",
       " 'evacuate',\n",
       " 'change',\n",
       " 'call',\n",
       " 'bus',\n",
       " 'as',\n",
       " 'wild',\n",
       " 'sinking',\n",
       " 'severe',\n",
       " 'refugee',\n",
       " 'oil',\n",
       " 'military',\n",
       " 'head',\n",
       " 'confirmed',\n",
       " 'child',\n",
       " 'update',\n",
       " 'terrorist',\n",
       " 'reddit',\n",
       " 'minute',\n",
       " 'little',\n",
       " 'free',\n",
       " 'face',\n",
       " 'explosion',\n",
       " 'derailment',\n",
       " 'coming',\n",
       " 'bad',\n",
       " 'always',\n",
       " 'well',\n",
       " 'panic',\n",
       " 'outbreak',\n",
       " 'natural',\n",
       " 'murder',\n",
       " 'migrant',\n",
       " 'made',\n",
       " 'keep',\n",
       " 'injured',\n",
       " 'hope',\n",
       " 'end',\n",
       " 'earthquake',\n",
       " 'check',\n",
       " 'smoke',\n",
       " 'set',\n",
       " 'run',\n",
       " 'rain',\n",
       " 'job',\n",
       " 'ive',\n",
       " 'game',\n",
       " 'failure',\n",
       " 'eye',\n",
       " 'everyone',\n",
       " 'thunder',\n",
       " 'riot',\n",
       " 'next',\n",
       " 'market',\n",
       " 'hurricane',\n",
       " 'he',\n",
       " 'explode',\n",
       " 'business',\n",
       " 'blood',\n",
       " 'big',\n",
       " 'attacked',\n",
       " 'area',\n",
       " 'ambulance',\n",
       " 'also',\n",
       " 'air',\n",
       " '70',\n",
       " '\\x89ûò',\n",
       " 'wrecked',\n",
       " 'wounded',\n",
       " 'whole',\n",
       " 'twister',\n",
       " 'tornado',\n",
       " 'tonight',\n",
       " 'survivor',\n",
       " 'summer',\n",
       " 'post',\n",
       " 'part',\n",
       " 'loud',\n",
       " 'lot',\n",
       " 'liked',\n",
       " 'lightning',\n",
       " 'heat',\n",
       " 'gon',\n",
       " 'destroy',\n",
       " 'charged',\n",
       " 'catastrophe',\n",
       " 'wreckage',\n",
       " 'w',\n",
       " 'violent',\n",
       " 'terrorism',\n",
       " 'survived',\n",
       " 'survive',\n",
       " 'stock',\n",
       " 'spill',\n",
       " 'sign',\n",
       " 'saudi',\n",
       " 'rescuer',\n",
       " 'released',\n",
       " 'red',\n",
       " 'heart',\n",
       " 'harm',\n",
       " 'dust',\n",
       " 'drought',\n",
       " 'august',\n",
       " 'windstorm',\n",
       " 'tragedy',\n",
       " 'someone',\n",
       " 'shot',\n",
       " 'save',\n",
       " 'phone',\n",
       " 'order',\n",
       " 'landslide',\n",
       " 'hail',\n",
       " 'destroyed',\n",
       " 'curfew',\n",
       " 'collided',\n",
       " 'cliff',\n",
       " 'breaking',\n",
       " 'boat',\n",
       " 'baby',\n",
       " '40',\n",
       " 'week',\n",
       " 'structural',\n",
       " 'saw',\n",
       " 'sandstorm',\n",
       " 'rescue',\n",
       " 'oh',\n",
       " 'missing',\n",
       " 'massacre',\n",
       " 'island',\n",
       " 'horrible',\n",
       " 'high',\n",
       " 'fan',\n",
       " 'battle',\n",
       " 'word',\n",
       " 'white',\n",
       " 'trauma',\n",
       " 'thought',\n",
       " 'sinkhole',\n",
       " 'second',\n",
       " 'screaming',\n",
       " 'ruin',\n",
       " 'real',\n",
       " 'quarantined',\n",
       " 'quarantine',\n",
       " 'put',\n",
       " 'power',\n",
       " 'mosque',\n",
       " 'light',\n",
       " 'investigator',\n",
       " 'ill',\n",
       " 'hundred',\n",
       " 'hour',\n",
       " 'group',\n",
       " 'displaced',\n",
       " 'destruction',\n",
       " 'derail',\n",
       " 'crashed',\n",
       " 'apocalypse',\n",
       " 'airplane',\n",
       " 'affected',\n",
       " 'trapped',\n",
       " 'must',\n",
       " 'lava',\n",
       " 'lady',\n",
       " 'kid',\n",
       " 'issue',\n",
       " 'friend',\n",
       " 'engulfed',\n",
       " 'effect',\n",
       " 'danger',\n",
       " 'collapsed',\n",
       " 'china',\n",
       " 'came',\n",
       " 'book',\n",
       " 'blown',\n",
       " 'away',\n",
       " '15',\n",
       " 'zone',\n",
       " 'wan',\n",
       " 'used',\n",
       " 'typhoon',\n",
       " 'trouble',\n",
       " 'send',\n",
       " 'reunion',\n",
       " 'responder',\n",
       " 'rescued',\n",
       " 'pic',\n",
       " 'national',\n",
       " 'mudslide',\n",
       " 'long',\n",
       " 'land',\n",
       " 'iran',\n",
       " 'inundated',\n",
       " 'hazard',\n",
       " 'fuck',\n",
       " 'famine',\n",
       " 'drowning',\n",
       " 'devastation',\n",
       " 'deluge',\n",
       " 'better',\n",
       " 'armageddon',\n",
       " 'airport',\n",
       " 'volcano',\n",
       " 'use',\n",
       " 'twitter',\n",
       " 'traumatised',\n",
       " 'thank',\n",
       " 'team',\n",
       " 'sure',\n",
       " 'sunk',\n",
       " 'start',\n",
       " 'site',\n",
       " 'ship',\n",
       " 'screamed',\n",
       " 'rioting',\n",
       " 'person',\n",
       " 'panicking',\n",
       " 'obliterated',\n",
       " 'men',\n",
       " 'meltdown',\n",
       " 'id',\n",
       " 'hijacking',\n",
       " 'hazardous',\n",
       " 'government',\n",
       " 'flattened',\n",
       " 'exploded',\n",
       " 'derailed',\n",
       " 'crush',\n",
       " 'cool',\n",
       " 'care',\n",
       " 'bridge',\n",
       " 'bagging',\n",
       " 'around',\n",
       " 'annihilated',\n",
       " '9',\n",
       " 'went',\n",
       " 'tsunami',\n",
       " 'sue',\n",
       " 'song',\n",
       " 'river',\n",
       " 'razed',\n",
       " 'place',\n",
       " 'ok',\n",
       " 'obliteration',\n",
       " 'obliterate',\n",
       " 'music',\n",
       " 'memory',\n",
       " 'isi',\n",
       " 'electrocuted',\n",
       " 'drown',\n",
       " 'died',\n",
       " 'detonate',\n",
       " 'desolation',\n",
       " 'collision',\n",
       " 'collide',\n",
       " 'chemical',\n",
       " 'caused',\n",
       " 'calgary',\n",
       " 'bombed',\n",
       " 'bang',\n",
       " 'wound',\n",
       " 'ur',\n",
       " 'upheaval',\n",
       " 'tree',\n",
       " 'street',\n",
       " 'st',\n",
       " 'south',\n",
       " 'side',\n",
       " 'shoulder',\n",
       " 'security',\n",
       " 'scream',\n",
       " 'reason',\n",
       " 'policy',\n",
       " 'pkk',\n",
       " 'past',\n",
       " 'mp',\n",
       " 'medium',\n",
       " 'making',\n",
       " 'least',\n",
       " 'la',\n",
       " 'horror',\n",
       " 'fight',\n",
       " 'evacuated',\n",
       " 'due',\n",
       " 'drowned',\n",
       " 'didnt',\n",
       " 'deal',\n",
       " 'crushed',\n",
       " 'crew',\n",
       " 'county',\n",
       " 'country',\n",
       " 'burned',\n",
       " 'blew',\n",
       " 'beautiful',\n",
       " 'anniversary',\n",
       " 'yet',\n",
       " 'whirlwind',\n",
       " 'v',\n",
       " 'trying',\n",
       " 'three',\n",
       " 'suspect',\n",
       " 'stay',\n",
       " 'soon',\n",
       " 'something',\n",
       " 'rainstorm',\n",
       " 'possible',\n",
       " 'officer',\n",
       " 'north',\n",
       " 'nigga',\n",
       " 'murderer',\n",
       " 'line',\n",
       " 'islam',\n",
       " 'india',\n",
       " 'hell',\n",
       " 'heard',\n",
       " 'fun',\n",
       " 'find',\n",
       " 'feeling',\n",
       " 'fedex',\n",
       " 'electrocute',\n",
       " 'ebay',\n",
       " 'detonation',\n",
       " 'cyclone',\n",
       " 'catastrophic',\n",
       " 'case',\n",
       " 'blazing',\n",
       " 'blast',\n",
       " 'bc',\n",
       " 'almost',\n",
       " '8',\n",
       " '6',\n",
       " 'traffic',\n",
       " 'snowstorm',\n",
       " 'prebreak',\n",
       " 'play',\n",
       " 'plane',\n",
       " 'pandemonium',\n",
       " 'nowplaying',\n",
       " 'name',\n",
       " 'move',\n",
       " 'mean',\n",
       " 'longer',\n",
       " 'level',\n",
       " 'left',\n",
       " 'israeli',\n",
       " 'inside',\n",
       " 'hellfire',\n",
       " 'helicopter',\n",
       " 'hear',\n",
       " 'handbag',\n",
       " 'half',\n",
       " 'gun',\n",
       " 'done',\n",
       " 'detonated',\n",
       " 'demolished',\n",
       " 'computer',\n",
       " 'bleeding',\n",
       " 'believe',\n",
       " 'american',\n",
       " '\\x89ûó',\n",
       " 'yes',\n",
       " 'west',\n",
       " 'wait',\n",
       " 'swallowed',\n",
       " 'star',\n",
       " 'remember',\n",
       " 'nothing',\n",
       " 'lost',\n",
       " 'history',\n",
       " 'hijack',\n",
       " 'health',\n",
       " 'flag',\n",
       " 'far',\n",
       " 'expert',\n",
       " 'doesnt',\n",
       " 'demolish',\n",
       " 'deluged',\n",
       " 'declares',\n",
       " 'couple',\n",
       " 'bioterror',\n",
       " 'america',\n",
       " 'aircraft',\n",
       " '16yr',\n",
       " 'win',\n",
       " 'turkey',\n",
       " 'thanks',\n",
       " 'support',\n",
       " 'soudelor',\n",
       " 'seismic',\n",
       " 'rubble',\n",
       " 'rock',\n",
       " 'rise',\n",
       " 'problem',\n",
       " 'month',\n",
       " 'moment',\n",
       " 'maybe',\n",
       " 'human',\n",
       " 'hijacker',\n",
       " 'hey',\n",
       " 'hand',\n",
       " 'firefighter',\n",
       " 'dog',\n",
       " 'data',\n",
       " 'conclusively',\n",
       " 'christian',\n",
       " 'center',\n",
       " 'bush',\n",
       " 'brown',\n",
       " 'bar',\n",
       " 'avalanche',\n",
       " 'anything',\n",
       " 'actually',\n",
       " 'action',\n",
       " 'abc',\n",
       " '50',\n",
       " '20',\n",
       " 'yeah',\n",
       " 'wont',\n",
       " 'whats',\n",
       " 'victim',\n",
       " 'vehicle',\n",
       " 'typhoondevastated',\n",
       " 'texas',\n",
       " 'tell',\n",
       " 'talk',\n",
       " 'spot',\n",
       " 'shooting',\n",
       " 'secret',\n",
       " 'saved',\n",
       " 'saipan',\n",
       " 're\\x89û',\n",
       " 'reuters',\n",
       " 'rd',\n",
       " 'r',\n",
       " 'probably',\n",
       " 'outside',\n",
       " 'others',\n",
       " 'nearby',\n",
       " 'n',\n",
       " 'low',\n",
       " 'literally',\n",
       " 'lie',\n",
       " 'huge',\n",
       " 'flash',\n",
       " 'eyewitness',\n",
       " 'die',\n",
       " 'demolition',\n",
       " 'crisis',\n",
       " 'control',\n",
       " 'coach',\n",
       " 'blaze',\n",
       " 'bioterrorism',\n",
       " 'ball',\n",
       " 'arson',\n",
       " 'amid',\n",
       " 'already',\n",
       " '7',\n",
       " '12',\n",
       " 'youth',\n",
       " 'village',\n",
       " 'tomorrow',\n",
       " 'thousand',\n",
       " 'space',\n",
       " 'searching',\n",
       " 'reactor',\n",
       " 'picking',\n",
       " 'peace',\n",
       " 'omg',\n",
       " 'money',\n",
       " 'million',\n",
       " 'mark',\n",
       " 'manslaughter',\n",
       " 'leather',\n",
       " 'lab',\n",
       " 'gt',\n",
       " 'drive',\n",
       " 'desolate',\n",
       " 'course',\n",
       " 'chance',\n",
       " 'blight',\n",
       " 'bigger',\n",
       " 'become',\n",
       " '11yearold',\n",
       " 'wrong',\n",
       " 'watching',\n",
       " 'tweet',\n",
       " 'turn',\n",
       " 'trench',\n",
       " 'though',\n",
       " 'theyre',\n",
       " 'stretcher',\n",
       " 'spring',\n",
       " 'seek',\n",
       " 'russian',\n",
       " 'projected',\n",
       " 'okay',\n",
       " 'nw',\n",
       " 'muslim',\n",
       " 'meek',\n",
       " 'mayhem',\n",
       " 'major',\n",
       " 'idea',\n",
       " 'hat',\n",
       " 'giant',\n",
       " 'everything',\n",
       " 'disea',\n",
       " 'damn',\n",
       " 'called',\n",
       " 'across',\n",
       " '30',\n",
       " '25',\n",
       " 'usa',\n",
       " 'tv',\n",
       " 'totally',\n",
       " 'temple',\n",
       " 'taken',\n",
       " 'stand',\n",
       " 'soul',\n",
       " 'share',\n",
       " 'self',\n",
       " 'running',\n",
       " 'rule',\n",
       " 'refugio',\n",
       " 'radio',\n",
       " 'pretty',\n",
       " 'passenger',\n",
       " 'offensive',\n",
       " 'nearly',\n",
       " 'mount',\n",
       " 'mom',\n",
       " 'lord',\n",
       " 'leave',\n",
       " 'lead',\n",
       " 'knock',\n",
       " 'instead',\n",
       " 'hollywood',\n",
       " 'hate',\n",
       " 'hard',\n",
       " 'hailstorm',\n",
       " 'gem',\n",
       " 'force',\n",
       " 'finally',\n",
       " 'dude',\n",
       " 'driver',\n",
       " 'crazy',\n",
       " 'costlier',\n",
       " 'company',\n",
       " 'caught',\n",
       " 'banned',\n",
       " 'alone',\n",
       " 'ago',\n",
       " 'ablaze',\n",
       " 'wall',\n",
       " 'united',\n",
       " 'uk',\n",
       " 'try',\n",
       " 'trust',\n",
       " 'sky',\n",
       " 'reddits',\n",
       " 'quiz',\n",
       " 'property',\n",
       " 'poor',\n",
       " 'online',\n",
       " 'number',\n",
       " 'miner',\n",
       " 'might',\n",
       " 'mad',\n",
       " 'looking',\n",
       " 'learn',\n",
       " 'large',\n",
       " 'issued',\n",
       " 'isnt',\n",
       " 'insurance',\n",
       " 'ignition',\n",
       " 'hero',\n",
       " 'happy',\n",
       " 'global',\n",
       " 'fukushima',\n",
       " 'feared',\n",
       " 'favorite',\n",
       " 'entire',\n",
       " 'emmerdale',\n",
       " 'east',\n",
       " 'drake',\n",
       " 'daily',\n",
       " 'comment',\n",
       " 'closed',\n",
       " 'camp',\n",
       " 'cake',\n",
       " 'bring',\n",
       " 'blue',\n",
       " 'bestnaijamade',\n",
       " 'begin',\n",
       " 'beach',\n",
       " 'aug',\n",
       " 'anyone',\n",
       " 'annihilation',\n",
       " 'angry',\n",
       " 'added',\n",
       " '05',\n",
       " 'wow',\n",
       " 'wonder',\n",
       " 'wake',\n",
       " 'virgin',\n",
       " 'view',\n",
       " 'transport',\n",
       " 'town',\n",
       " 'toddler',\n",
       " 'taking',\n",
       " 'subreddits',\n",
       " 'shift',\n",
       " 'shes',\n",
       " 'seen',\n",
       " 'seeing',\n",
       " 'sea',\n",
       " 'scene',\n",
       " 'scared',\n",
       " 'russia',\n",
       " 'risk',\n",
       " 'ready',\n",
       " 'pradesh',\n",
       " 'point',\n",
       " 'pick',\n",
       " 'pay',\n",
       " 'pain',\n",
       " 'p',\n",
       " 'outrage',\n",
       " 'open',\n",
       " 'madhya',\n",
       " 'link',\n",
       " 'lake',\n",
       " 'heavy',\n",
       " 'haha',\n",
       " 'green',\n",
       " 'gop',\n",
       " 'gbbo',\n",
       " 'front',\n",
       " 'france',\n",
       " 'former',\n",
       " 'flight',\n",
       " 'film',\n",
       " 'fast',\n",
       " 'earth',\n",
       " 'disease',\n",
       " 'devastated',\n",
       " 'desire',\n",
       " 'declaration',\n",
       " 'cover',\n",
       " 'cop',\n",
       " 'cnn',\n",
       " 'class',\n",
       " 'claim',\n",
       " 'civilian',\n",
       " 'blizzard',\n",
       " 'bbc',\n",
       " 'b',\n",
       " 'australia',\n",
       " 'ancient',\n",
       " 'aint',\n",
       " 'aftershock',\n",
       " '13',\n",
       " '10',\n",
       " 'worst',\n",
       " 'wednesday',\n",
       " 'wasnt',\n",
       " 'unit',\n",
       " 'turned',\n",
       " 'truth',\n",
       " 'tote',\n",
       " 'thinking',\n",
       " 'super',\n",
       " 'sorry',\n",
       " 'season',\n",
       " 'rly',\n",
       " 'question',\n",
       " 'public',\n",
       " 'pray',\n",
       " 'playing',\n",
       " 'planned',\n",
       " 'piece',\n",
       " 'pamela',\n",
       " 'pakistan',\n",
       " 'nigerian',\n",
       " 'mountain',\n",
       " 'mop',\n",
       " 'mode',\n",
       " 'miss',\n",
       " 'med',\n",
       " 'led',\n",
       " 'lamp',\n",
       " 'image',\n",
       " 'govt',\n",
       " 'glad',\n",
       " 'galactic',\n",
       " 'funtenna',\n",
       " 'enough',\n",
       " 'else',\n",
       " 'downtown',\n",
       " 'don\\x89ûªt',\n",
       " 'deep',\n",
       " 'cree',\n",
       " 'chile',\n",
       " 'cdt',\n",
       " 'cat',\n",
       " 'burn',\n",
       " 'british',\n",
       " 'break',\n",
       " 'biggest',\n",
       " 'bed',\n",
       " 'art',\n",
       " 'arrested',\n",
       " 'animal',\n",
       " 'act',\n",
       " '11',\n",
       " 'young',\n",
       " 'working',\n",
       " 'waving',\n",
       " 'tried',\n",
       " 'track',\n",
       " 'threat',\n",
       " 'theater',\n",
       " 'terror',\n",
       " 'safety',\n",
       " 'sad',\n",
       " 'reported',\n",
       " 'recount',\n",
       " 'potus',\n",
       " 'playlist',\n",
       " 'philippine',\n",
       " 'patience',\n",
       " 'party',\n",
       " 'parent',\n",
       " 'pakistani',\n",
       " 'occurred',\n",
       " 'nice',\n",
       " 'nagasaki',\n",
       " 'mph',\n",
       " 'mod',\n",
       " 'militant',\n",
       " 'middle',\n",
       " 'mention',\n",
       " 'member',\n",
       " 'lmao',\n",
       " 'likely',\n",
       " 'israel',\n",
       " 'horse',\n",
       " 'holding',\n",
       " 'helping',\n",
       " 'happened',\n",
       " 'give',\n",
       " 'geller',\n",
       " 'gave',\n",
       " 'gas',\n",
       " 'friday',\n",
       " 'foot',\n",
       " 'fashion',\n",
       " 'fact',\n",
       " 'escape',\n",
       " 'ebola',\n",
       " 'driving',\n",
       " 'denver',\n",
       " 'date',\n",
       " 'dance',\n",
       " 'cut',\n",
       " 'cry',\n",
       " 'cost',\n",
       " 'colorado',\n",
       " 'character',\n",
       " 'career',\n",
       " 'capture',\n",
       " 'ca',\n",
       " 'ave',\n",
       " 'arsonist',\n",
       " 'appears',\n",
       " 'apollo',\n",
       " 'alarm',\n",
       " 'account',\n",
       " '70th',\n",
       " '16',\n",
       " '12000',\n",
       " 'york',\n",
       " 'worry',\n",
       " 'wedding',\n",
       " 'wanted',\n",
       " 'version',\n",
       " 'using',\n",
       " 'true',\n",
       " 'took',\n",
       " 'thursday',\n",
       " 'text',\n",
       " 'teen',\n",
       " 'target',\n",
       " 'strike',\n",
       " 'standard',\n",
       " 'soldier',\n",
       " 'small',\n",
       " 'single',\n",
       " 'sex',\n",
       " 'room',\n",
       " 'release',\n",
       " 'record',\n",
       " 'rate',\n",
       " 'queen',\n",
       " 'provoke',\n",
       " 'price',\n",
       " 'ppl',\n",
       " 'pilot',\n",
       " 'park',\n",
       " 'offroad',\n",
       " 'myanmar',\n",
       " 'morning',\n",
       " 'mile',\n",
       " 'metal',\n",
       " 'meet',\n",
       " 'listen',\n",
       " ...]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_vectorizer.get_vocabulary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "5c7d623e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text_vectorizer.get_vocabulary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "57fae588",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top_words ['', '[UNK]', 'like', 'fire', 'im', 'amp', 'u', 'get', 'via', 'new']\n",
      "lowest words ['judicial', 'judgement', 'judemugabi', 'juda', 'juanny', 'juanmthompson', 'juan', 'jtw', 'jtruff23', 'jsunnews']\n"
     ]
    }
   ],
   "source": [
    "words = text_vectorizer.get_vocabulary()\n",
    "top_words = words[:10]\n",
    "print(\"top_words\" , top_words)\n",
    "lowest_words = words[-10:]\n",
    "print(\"lowest words\" , lowest_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "887f609e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "e2daa4e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.layers.core.embedding.Embedding at 0x25cb40119d0>"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.random.set_seed(42)\n",
    "embedding = layers.Embedding(input_dim = max_tokens,\n",
    "                             input_length=max_sent_length,\n",
    "                             output_dim=128,\n",
    "                             embeddings_initializer = \"uniform\",\n",
    "                             name = \"embedding_1\"\n",
    "                            )\n",
    "embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "d36d86d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random sent is  drowned kiddie pool lost ploppy\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 10, 128), dtype=float32, numpy=\n",
       "array([[[-0.03048784,  0.04003957,  0.01426423, ...,  0.04380543,\n",
       "         -0.01184901,  0.04811785],\n",
       "        [-0.01329229, -0.0147266 ,  0.00419713, ..., -0.03373086,\n",
       "         -0.01940848, -0.02834207],\n",
       "        [ 0.00668001, -0.04291473,  0.00131118, ...,  0.04559691,\n",
       "          0.0180651 , -0.0089489 ],\n",
       "        ...,\n",
       "        [ 0.03977952, -0.03782602, -0.03646283, ...,  0.00236253,\n",
       "          0.03332629,  0.02803668],\n",
       "        [ 0.03977952, -0.03782602, -0.03646283, ...,  0.00236253,\n",
       "          0.03332629,  0.02803668],\n",
       "        [ 0.01645621, -0.00589932, -0.01471175, ..., -0.02511839,\n",
       "          0.00912381, -0.00024097]]], dtype=float32)>"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_sent = random.choice(x_train)\n",
    "print(\"random sent is \" , rand_sent)\n",
    "sample_embedding = embedding(text_vectorizer([random_sent]))\n",
    "sample_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "056992fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(128,), dtype=float32, numpy=\n",
       "array([-0.03048784,  0.04003957,  0.01426423, -0.009557  ,  0.02617123,\n",
       "       -0.0296874 , -0.00520356, -0.0015491 , -0.0432423 ,  0.03947959,\n",
       "       -0.01599623, -0.00307544,  0.03297296,  0.00674161,  0.00999154,\n",
       "       -0.01785795, -0.01865766, -0.00477596,  0.00252626, -0.03301965,\n",
       "       -0.02574833, -0.02735887,  0.04895354, -0.02428398, -0.03284209,\n",
       "       -0.01870733,  0.00711773,  0.01872716, -0.00550957, -0.03287035,\n",
       "        0.00234555,  0.04410351, -0.03565437, -0.01922593,  0.02827149,\n",
       "        0.0436686 ,  0.00345143, -0.0235054 , -0.04512234,  0.04664881,\n",
       "        0.00074053, -0.03666414, -0.00098949, -0.00345348,  0.01539921,\n",
       "        0.02117733, -0.04298643,  0.04409125, -0.03413866, -0.03797597,\n",
       "       -0.02278177, -0.03870352,  0.0427174 ,  0.01543829,  0.0360924 ,\n",
       "       -0.03057199, -0.03195395, -0.02997066, -0.01305727,  0.02030683,\n",
       "       -0.00475283,  0.03603263, -0.01161944,  0.04248586,  0.02816181,\n",
       "       -0.03061599, -0.01718662,  0.01664113,  0.00401932,  0.016686  ,\n",
       "       -0.02431662,  0.01283738,  0.00842275, -0.01787064, -0.04026625,\n",
       "        0.01700953,  0.03075801, -0.0321009 ,  0.01825389,  0.00362983,\n",
       "       -0.03756738, -0.01746333,  0.00938957, -0.04698051,  0.02837597,\n",
       "       -0.01724213, -0.00334834,  0.0484197 , -0.0189404 , -0.04249438,\n",
       "        0.01246013,  0.02314344,  0.01160693,  0.02660486,  0.03838194,\n",
       "        0.02497557,  0.04963852, -0.00935186, -0.01292033, -0.01474001,\n",
       "       -0.03959584, -0.02816646, -0.00675805,  0.00732044, -0.01892152,\n",
       "       -0.01354529, -0.02233988, -0.00367675,  0.01236979, -0.00894438,\n",
       "        0.00851694,  0.03830599,  0.00906576, -0.00740876,  0.02249689,\n",
       "        0.04745707, -0.04637178,  0.03849233,  0.02430839, -0.03302344,\n",
       "        0.04582838,  0.00117537, -0.03440595, -0.03007348, -0.00831386,\n",
       "        0.04380543, -0.01184901,  0.04811785], dtype=float32)>"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sample_embedding for single token\n",
    "sample_embedding[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "41c08d9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10, 128), dtype=float32, numpy=\n",
       "array([[-0.03048784,  0.04003957,  0.01426423, ...,  0.04380543,\n",
       "        -0.01184901,  0.04811785],\n",
       "       [-0.01329229, -0.0147266 ,  0.00419713, ..., -0.03373086,\n",
       "        -0.01940848, -0.02834207],\n",
       "       [ 0.00668001, -0.04291473,  0.00131118, ...,  0.04559691,\n",
       "         0.0180651 , -0.0089489 ],\n",
       "       ...,\n",
       "       [ 0.03977952, -0.03782602, -0.03646283, ...,  0.00236253,\n",
       "         0.03332629,  0.02803668],\n",
       "       [ 0.03977952, -0.03782602, -0.03646283, ...,  0.00236253,\n",
       "         0.03332629,  0.02803668],\n",
       "       [ 0.01645621, -0.00589932, -0.01471175, ..., -0.02511839,\n",
       "         0.00912381, -0.00024097]], dtype=float32)>"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sample_embedding for single doc(tweet)\n",
    "sample_embedding[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "58f795df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2710    detonation fashionable mountaineering electron...\n",
       "3250    men escape car engulfed flame parley canyon cr...\n",
       "78      i77 mile marker 31 40 south mooresville iredel...\n",
       "1621    greece tax revenue collapse debt crisis contin...\n",
       "2528    afraid sudden fear neither desolation wicked c...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "b8bd895d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix , accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "b5cb8f9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tfidf', TfidfVectorizer()), ('clf', MultinomialNB())])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_0 = Pipeline([\n",
    "                    (\"tfidf\", TfidfVectorizer()), # convert words to numbers using tfidf\n",
    "                    (\"clf\", MultinomialNB()) # model the text\n",
    "])\n",
    "model_0.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "332d7e81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, ..., 1, 0, 1], dtype=int64)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model_0.predict(x_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "b0304428",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2284,)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "7a7ae3c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1164,   97],\n",
       "       [ 379,  644]], dtype=int64)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conf = confusion_matrix(y_test , y_pred)\n",
    "conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "a0783bdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "79.15936952714536"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test , y_pred)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83afc46f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
