{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "397bd4a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ba3c55f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "659cdc54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.22658336,  1.100993  ,  0.5837281 ,  0.12573567, -0.04194349,\n",
       "        1.25419   , -0.18515149, -0.12617828,  0.27460775, -0.97325325,\n",
       "       -1.14499   , -1.0881562 , -1.1850882 , -0.5404191 ,  1.0472636 ,\n",
       "       -0.9579065 ,  0.63289726,  0.59963953,  0.03954166, -0.02705175,\n",
       "        1.1544387 , -0.4932379 ,  0.41934192,  2.2605495 ,  2.1551492 ,\n",
       "        0.94307667,  0.42828968,  0.2111451 ,  0.8446547 , -0.4425388 ,\n",
       "       -0.93836755, -0.48350883, -0.31315064, -0.8614874 , -1.0899724 ,\n",
       "        1.2357535 ,  0.57367146,  0.5103008 , -0.5884206 ,  0.8978859 ,\n",
       "        0.56623805,  0.47870752,  0.46202406, -0.87375057, -0.63017255,\n",
       "       -0.32474768, -0.03315104, -0.03459805,  1.9891664 , -0.19057423,\n",
       "       -0.39528927, -2.291253  , -0.88064474, -1.1186571 , -0.2921518 ,\n",
       "       -1.9983381 , -1.1098228 , -0.08781472,  0.3100487 , -0.01400977,\n",
       "        1.0273129 , -0.55071014, -0.6101234 , -1.4144171 ,  0.7187637 ,\n",
       "        0.3039726 , -0.08009079,  0.39419177, -0.24585962, -1.2377728 ,\n",
       "        1.0913045 ,  0.6683823 , -0.05125841,  0.5777097 , -0.51491654,\n",
       "        0.10127291,  1.7347126 ,  0.2861041 , -1.2565283 , -0.17166   ,\n",
       "       -0.8184233 , -0.9064088 , -0.27560234, -0.16391398, -1.1984334 ,\n",
       "        0.09277029, -0.04694098,  0.23942217, -2.282131  ,  2.382982  ,\n",
       "       -0.85767865, -0.26747304,  0.36839265,  0.16892366,  1.1782364 ,\n",
       "        0.75653464], dtype=float32)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp(\"brave\").vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6d9c8ece",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.9294753 ,  0.9105551 ,  0.78658164, -0.65685034,  0.22026835,\n",
       "        0.66672397, -0.33517247, -0.32130057,  1.4379277 , -0.7271727 ,\n",
       "       -0.21908721, -0.5976988 ,  0.75697124,  0.47066244, -0.39437163,\n",
       "       -0.31610283,  0.23048098,  0.83343947, -0.64916295, -0.19686425,\n",
       "       -0.03249754, -0.75137746,  0.47989956,  1.7394655 ,  2.0289788 ,\n",
       "        0.5302725 ,  0.21387792, -0.84599817,  0.23282254,  0.29437706,\n",
       "       -0.14906892,  0.22031564, -1.2843657 , -0.55383646, -0.7562144 ,\n",
       "        1.0973754 , -0.36016685, -0.36616647,  0.31590363, -0.08223943,\n",
       "        0.08984882, -0.48772618, -1.2562959 , -0.10777035, -0.5158826 ,\n",
       "       -1.3464925 ,  0.84696984,  1.166314  , -0.03405762,  0.344096  ,\n",
       "       -0.27696675, -2.263014  , -1.2906889 , -1.0021667 , -0.56893766,\n",
       "       -0.86988276, -0.8130194 , -0.8542992 , -0.06663238, -0.25265238,\n",
       "        0.5492479 , -0.2959315 ,  0.16792366, -0.81499565, -0.44643214,\n",
       "        0.46867222, -0.51185244,  1.080358  , -0.6676346 , -1.5150689 ,\n",
       "        0.79342806, -0.2985952 ,  0.40712407,  0.2788492 ,  0.17026228,\n",
       "        0.34967047,  0.00971347,  0.59894145, -0.4660567 ,  2.076467  ,\n",
       "       -0.53373945, -1.1251254 , -0.52337325,  0.28318417,  0.83731234,\n",
       "        1.1390566 ,  0.697065  ,  0.16238195, -1.4221202 ,  1.127598  ,\n",
       "       -1.1862413 , -0.11948717, -0.3920899 ,  0.40765464,  0.36961025,\n",
       "        1.0222874 ], dtype=float32)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp(\"lion\").vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2d9ad804",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.5128661 ,  0.02660337,  0.36815   , -0.32921705, -0.19396469,\n",
       "        0.70262307, -0.64046884,  0.12537146,  0.96640813, -0.4674626 ,\n",
       "        0.01165587, -0.4371189 ,  1.0533595 ,  0.00982711, -0.37151262,\n",
       "       -1.0154752 , -0.64291096,  1.1880711 ,  0.47923037,  0.9545528 ,\n",
       "        0.8774935 ,  0.3931822 , -0.64031124,  1.8654537 ,  0.9991021 ,\n",
       "        1.1925209 ,  1.8388946 , -1.221806  ,  1.9300038 ,  1.1396853 ,\n",
       "        0.52388054, -0.3857929 , -2.198627  , -0.8330496 , -0.64579654,\n",
       "        0.5177202 , -0.93055594, -0.7699339 , -0.5828929 ,  0.05384904,\n",
       "        0.09950055,  0.12999934, -0.66272545, -1.2067555 , -0.7263277 ,\n",
       "       -1.190656  ,  0.1671527 ,  0.78993714,  0.01245582, -0.00841342,\n",
       "       -0.07131507, -1.4842353 , -1.572545  , -1.2850642 , -0.58754885,\n",
       "       -0.52701294, -1.8505361 , -0.59038365, -0.28898886,  0.29369736,\n",
       "       -1.5960531 ,  0.06920565,  0.7526375 ,  0.6132613 , -0.48378497,\n",
       "       -0.5048829 , -0.8567926 ,  2.1814218 ,  0.01967054, -1.4870852 ,\n",
       "        0.9128076 ,  0.88886374,  1.0614955 , -0.7439398 ,  0.3051464 ,\n",
       "        0.48263067,  0.52667874,  1.2164841 , -0.24543577,  1.3823159 ,\n",
       "       -0.0708784 , -1.7966114 ,  0.77914906, -0.3771528 ,  0.4647894 ,\n",
       "        0.6532761 , -0.10809152, -0.03296027, -1.4471009 ,  2.2369075 ,\n",
       "       -1.5583063 , -1.2910483 , -0.22083803,  0.9253693 ,  0.31578338,\n",
       "        1.1546099 ], dtype=float32)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp(\"tiger\").vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8b0bed11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nlp(\"lion\").vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ec482690",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc1 = nlp(\"lion cat pet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "da5f3bfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lion   lion   1.0\n",
      "lion   cat   0.522598385810852\n",
      "lion   pet   0.15292394161224365\n",
      "cat   lion   0.522598385810852\n",
      "cat   cat   1.0\n",
      "cat   pet   0.3499341905117035\n",
      "pet   lion   0.15292394161224365\n",
      "pet   cat   0.3499341905117035\n",
      "pet   pet   1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Abdelrahman\\AppData\\Local\\Temp\\ipykernel_7000\\2618085643.py:3: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Token.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
      "  print(token1.text , \" \" ,token2.text, \" \" , token1.similarity(token2))\n"
     ]
    }
   ],
   "source": [
    "for token1 in doc1:\n",
    "    for token2 in doc1:\n",
    "        print(token1.text , \" \" ,token2.text, \" \" , token1.similarity(token2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8f287b5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "man        man       1.0\n",
      "man        monkey       0.6464224457740784\n",
      "man        book       0.6450545787811279\n",
      "man        laptop       0.15114016830921173\n",
      "monkey        man       0.6464224457740784\n",
      "monkey        monkey       1.0\n",
      "monkey        book       0.6465013027191162\n",
      "monkey        laptop       0.030758347362279892\n",
      "book        man       0.6450545787811279\n",
      "book        monkey       0.6465013027191162\n",
      "book        book       1.0\n",
      "book        laptop       0.3067266047000885\n",
      "laptop        man       0.15114016830921173\n",
      "laptop        monkey       0.030758347362279892\n",
      "laptop        book       0.3067266047000885\n",
      "laptop        laptop       1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Abdelrahman\\AppData\\Local\\Temp\\ipykernel_7000\\3044463868.py:4: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Token.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
      "  print(token1.text,\"      \",token2.text,\"     \", token1.similarity(token2))\n"
     ]
    }
   ],
   "source": [
    "doc2 = nlp(\"man monkey book laptop\")\n",
    "for token1 in doc2:\n",
    "    for token2 in doc2:\n",
    "        print(token1.text,\"      \",token2.text,\"     \", token1.similarity(token2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d29f975a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Abdelrahman\\AppData\\Local\\Temp\\ipykernel_7000\\3791872613.py:1: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
      "  nlp(\"man\").similarity(nlp(\"woman\"))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7829636965933969"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp(\"man\").similarity(nlp(\"woman\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2bca2174",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Abdelrahman\\AppData\\Local\\Temp\\ipykernel_7000\\3591241864.py:1: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
      "  nlp(\"man\").similarity(nlp(\"pen\"))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6177194796113852"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp(\"man\").similarity(nlp(\"pen\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "701e1d15",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Abdelrahman\\AppData\\Local\\Temp\\ipykernel_7000\\2360505027.py:1: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
      "  nlp(\"woman\").similarity(nlp(\"moon\"))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5988351482453779"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp(\"woman\").similarity(nlp(\"moon\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "74e6fb84",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Abdelrahman\\AppData\\Local\\Temp\\ipykernel_7000\\1701190433.py:1: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
      "  nlp(\"tree\").similarity(nlp(\"brave\"))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.58281274174089"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp(\"tree\").similarity(nlp(\"brave\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "cbc812f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Abdelrahman\\AppData\\Local\\Temp\\ipykernel_7000\\1452215266.py:1: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
      "  nlp(\"love\").similarity(nlp(\"brave\"))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5863314702714567"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp(\"love\").similarity(nlp(\"brave\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "11c3b240",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Abdelrahman\\AppData\\Local\\Temp\\ipykernel_7000\\2593867778.py:1: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
      "  nlp(\"lion\").similarity(nlp(\"tiger\"))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6949207730963608"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp(\"lion\").similarity(nlp(\"tiger\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "87e6cc48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nlp.vocab.vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0a32817b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 0)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.vocab.vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "90ff6506",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Abdelrahman\\AppData\\Local\\Temp\\ipykernel_7000\\4124062287.py:1: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
      "  nlp(\"we visited the zoo and saw animals\").similarity(nlp(\"we saw monkey on the tree\"))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5962854053005011"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp(\"we visited the zoo and saw animals\").similarity(nlp(\"we saw monkey on the tree\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f0ff8151",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Abdelrahman\\AppData\\Local\\Temp\\ipykernel_7000\\1027247099.py:1: UserWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
      "  nlp(\"we visited the zoo and saw animals\").similarity(nlp(\"the motor is very speed\"))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.2692586456808013"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp(\"we visited the zoo and saw animals\").similarity(nlp(\"the motor is very speed\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "444a443d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import spatial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "c50ab3d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_similarity = lambda x, y: 1 - spatial.distance.cosine(x, y) \n",
    "king = nlp(\"king\").vector\n",
    "man = nlp('man').vector\n",
    "woman = nlp('woman').vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "c33a7631",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.21506178e+00,  7.47154176e-01, -4.53419685e-02, -5.97024977e-01,\n",
       "        6.23479605e-01,  9.15102959e-01, -3.28971744e-02, -5.45917332e-01,\n",
       "        1.51124203e+00, -1.12343872e+00, -3.86040390e-01, -5.57482362e-01,\n",
       "        9.13396478e-01, -1.21748067e-01, -3.61565351e-01, -7.62333572e-02,\n",
       "       -7.16075748e-02, -3.95672739e-01, -2.58750439e-01,  3.56138617e-01,\n",
       "        1.51559189e-01, -2.12040842e-02,  7.93196321e-01,  6.13172650e-01,\n",
       "        8.24666142e-01,  1.17043734e+00,  5.48232675e-01, -6.58798575e-01,\n",
       "        6.75043225e-01,  5.06099582e-01, -5.19297063e-01,  8.19557607e-01,\n",
       "       -1.28116989e+00,  1.10182256e-01, -3.71253073e-01,  1.13465333e+00,\n",
       "       -5.56437373e-02,  5.10596186e-02,  4.39545214e-01, -4.32593197e-01,\n",
       "        8.98725033e-01,  7.42383063e-01, -8.90365899e-01,  2.27481276e-01,\n",
       "       -9.17631030e-01, -1.18377519e+00, -3.18357080e-01,  5.71566582e-01,\n",
       "       -2.71046162e-01, -2.05067530e-01, -3.37248981e-01, -1.46580040e+00,\n",
       "       -1.29928076e+00, -1.80415237e+00, -9.18626785e-04,  1.08999081e-01,\n",
       "       -1.45741260e+00, -1.27648461e+00,  3.50818008e-01, -6.63731515e-01,\n",
       "        3.19514722e-01, -1.40393436e+00,  6.16642833e-01, -4.17453051e-03,\n",
       "        3.65353853e-01,  3.80050898e-01, -3.24181676e-01,  2.79130161e-01,\n",
       "       -5.76902390e-01, -1.60177231e+00,  8.83273005e-01,  3.39627922e-01,\n",
       "        5.37448645e-01,  2.35982150e-01,  4.75726366e-01,  2.76138961e-01,\n",
       "       -1.59274936e-02, -4.26691771e-02, -5.64538240e-01,  2.62676120e+00,\n",
       "        3.64573747e-01, -1.17219448e+00, -3.86630446e-02, -6.56981766e-01,\n",
       "        4.15994763e-01,  9.49930251e-01,  3.10276508e-01,  3.83399576e-01,\n",
       "       -8.35150003e-01,  9.42995429e-01, -1.15895391e+00, -9.43802372e-02,\n",
       "       -4.51491505e-01,  1.21598169e-01,  1.17050970e+00,  8.19588304e-02],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "king"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "c4bc056d",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_vector = king - man + woman \n",
    "computed_similarities = [] \n",
    "words = ['cat','apple','queen','castle','sea','shell','orange','phone' ,\n",
    "         'angry','book','white','land','study','crown','prince','dog', \n",
    "         'great','princess','elizabeth','wow','eat','dead','horrible'] \n",
    "for word in words: \n",
    "    similarity = cosine_similarity(new_vector,nlp(word).vector)\n",
    "    computed_similarities.append((word, similarity)) \n",
    "    computed_similarities = sorted(computed_similarities, key=lambda item: -item[1]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "c816a612",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word       princess       has similarity       0.6664025187492371\n",
      "Word       land       has similarity       0.6450207233428955\n",
      "Word       dog       has similarity       0.6347449421882629\n",
      "Word       prince       has similarity       0.5842504501342773\n",
      "Word       book       has similarity       0.5480126738548279\n",
      "Word       apple       has similarity       0.5140084028244019\n",
      "Word       study       has similarity       0.5088146328926086\n",
      "Word       sea       has similarity       0.4870975911617279\n",
      "Word       white       has similarity       0.4815122187137604\n",
      "Word       cat       has similarity       0.4758085012435913\n",
      "Word       phone       has similarity       0.47452905774116516\n",
      "Word       castle       has similarity       0.46657559275627136\n",
      "Word       shell       has similarity       0.3553227186203003\n",
      "Word       great       has similarity       0.35420307517051697\n",
      "Word       horrible       has similarity       0.3541770875453949\n",
      "Word       angry       has similarity       0.3205915689468384\n",
      "Word       dead       has similarity       0.27598515152931213\n",
      "Word       queen       has similarity       0.2704496383666992\n",
      "Word       orange       has similarity       0.24556317925453186\n",
      "Word       eat       has similarity       0.21360227465629578\n",
      "Word       elizabeth       has similarity       0.15849415957927704\n",
      "Word       crown       has similarity       0.12792345881462097\n",
      "Word       wow       has similarity       0.00864200945943594\n"
     ]
    }
   ],
   "source": [
    "for a,b in computed_similarities[:] : \n",
    "    print(f'Word       {a}       has similarity       {b}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b95f94e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
